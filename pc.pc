Index: .gitignore
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.gitignore b/.gitignore
--- a/.gitignore	(revision ccffed1d69c1e025eee3502f8a1a3c919fe4fb52)
+++ b/.gitignore	(date 1735639008079)
@@ -1,3 +1,4 @@
 .idea
 /ai-poc.iml
 .env
+/venv/
\ No newline at end of file
Index: init-vector.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/init-vector.py b/init-vector.py
new file mode 100644
--- /dev/null	(date 1735635217778)
+++ b/init-vector.py	(date 1735635217778)
@@ -0,0 +1,22 @@
+from dotenv import load_dotenv
+from langchain_community.document_loaders import TextLoader
+from langchain_community.embeddings import DashScopeEmbeddings
+from langchain_community.vectorstores import Chroma
+from langchain_text_splitters import RecursiveCharacterTextSplitter
+
+load_dotenv()
+
+loader = TextLoader("introduction.txt")
+docs = loader.load()
+
+text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
+splits = text_splitter.split_documents(docs)
+vectorstore = Chroma(
+    collection_name="ai_learning",
+    embedding_function=DashScopeEmbeddings(),
+    persist_directory="vectordb"
+)
+vectorstore.add_documents(splits)
+
+documents = vectorstore.similarity_search("专栏的作者是谁？")
+print(documents)
Index: introduction.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/introduction.txt b/introduction.txt
new file mode 100644
--- /dev/null	(date 1735637140692)
+++ b/introduction.txt	(date 1735637140692)
@@ -0,0 +1,71 @@
+**豚母升木之技理探析**
+
+**提要**
+本文旨在详究“豚母升木”这一奇象，从生物学、物理学及工艺学诸范畴剖析其可行性与实施途径。兼考豚母体格构造、习性行为、环境顺应及技艺手段，构建理论体系，并展望其潜在应用之愿景。斯文不仅为古谚添科学注脚，亦为畜牧与生态保护提供创新思路。
+
+**关键词**：豚母升木、生物妙理、物理玄机、工艺巧思、技艺探究
+
+---
+
+**壹、引言**
+昔人云：“豚母升木”，以喻事之难如登天。然今科技日新月异，往昔无稽之事渐成可期。故循科学之道，系统解析此象，求索成事之法，冀为后世研用者开一径。天地间万物皆有其道，唯人力可通幽达明，化不可能为可能。
+
+**贰、生物学解析**
+贰壹、豚母体格
+豚母，陆兽也，形短而圆，善行而非攀。重逾百钧，登高维艰。然若借人力改其筋骨，或基因修饰增肌，外甲助动，庶几能增其攀援之力，化不可能为可能。观自然造化，虽豚母拙于攀爬，却亦有灵猴捷于林梢，二者同处天地之间，各展其能，岂非妙哉？
+
+贰贰、行为考察
+豚母常居平野，觅食憩息，少有登木之举。然智者移山，驯导可变其性。诱饵引路，渐习攀登；正向激励，训练有方，使之克服畏难，终能登木。古人云：“勤能补拙”，诚如是也。通过耐心调教，豚母亦能展现其未曾发掘之潜能。
+
+**叁、物理学审视**
+参壹、力道解析
+豚母登木，力学难题重重。抗体重，需强健之力与协调。木之承载，尤为紧要。寻常乔木，恐难承豚之重。择橡松之类，固树干，增其负重，方可承豚母之躯。天地间，物有所载，各有其度，适得其所，则万事俱备。
+
+参貳、摩擦与稳定
+蹄足与木面之摩擦，关乎成败。增蹄之摩擦，如特材蹄套，稳其行；木面糙平，影响抓握。置防滑垫，增树皮糙度，以利豚母攀缘。恰似春雨润物细无声，细微之处见真章，摩擦之力虽微，却是豚母升木之关键所在。
+
+**肆、工艺学探讨**
+肆壹、辅具设计
+欲豚母升木，需备良器。造轻巧坚牢之梯架，助逐级而上；创智控系统，实时监控，适时助力。传感器配AI，分析姿态，机械施援，仿若神工。工欲善其事，必先利其器，以此等巧思，助豚母一臂之力，岂不美哉？
+
+肆贰、木艺改造
+为适豚之攀，木可改造。设阶减程，修枝整干，优化结构。模块化改造系统，量身定制，随豚而变，匠心独运。匠人之心，精雕细琢，使得树木亦能成为豚母之舞台，演绎一场别样的生态和谐剧。
+
+**伍、实际应用前瞻**
+伍壹、农畜业变革
+豚母升木之术，革农畜业之新。山林之地，借木而养，地利倍增。结合林业，资源互用，降本增效，天地同利。此乃农林共生之典范，既富且美，何乐而不为？
+
+伍贰、生态保护
+豚木共生，善用林资，地生得保。豚之活动，益树生长，相得益彰。粪肥树木，木荫豚母，循环互利，天人合一。如此和谐之美，宛如一幅自然画卷，令人赞叹不已。
+
+**陆、结语**
+本文豚母升木之多维剖析，绘就技术蓝图。虽前路多阻，科技日新，旧谚有望成真。后续研究，宜深究其实现与应用，为农畜、环保开新径。世间万物，皆有其道，人力所至，无不克难。
+
+**柒、历史与文化渊源**
+“豚母升木”，古语久传，喻事极难。今科技兴，旧难渐破。本文从科学视角，析此事象，究其可能与途径，供学术参考。古训新解，意在传承智慧，启迪未来。
+
+**捌、技术挑战与应对**
+捌壹、挑战重重
+豚体局限，木之承载，摩擦稳定，皆为难关。豚性与环境，亦需考量。然世事无绝对，唯有迎难而上，方能成就非凡。
+
+捌贰、应对策略
+针对难题，本文献策。改豚体，设辅具，改木艺，调豚性，以求登木之能。智者不惑，勇者不惧，面对挑战，当以智慧和勇气迎接。
+
+**玖、未来研究导向**
+未来，当更探豚木之术，精进辅具，优化工艺。研其对农畜、环保之影响，启新思。探索未知，永无止境，愿学者们继续前行，开辟新的天地。
+
+**拾、社会影响与道德权衡**
+豚木之术，影响深远。农畜增效，环保得宜。然道德考量，如豚福、生态风险，不可忽视。推广之际，需虑社会效应与道德，保持续正当。以人为本，兼顾自然，方能长久。
+
+**拾壹、结语**
+豚母升木之技理，虽难，科技可期。未来研究，宜深究其实现与应用，为农畜、环保开新径。世间之事，难易相成，惟有不懈追求，方能化难为易，创造奇迹。
+
+**参考文献**
+[1] 张三, 李四. 行为学与驯导艺术[M]. 北京: 学术出版社, 2020.
+[2] 王五, 赵六. 力学与工艺应用[J]. 工艺学刊, 2019, 35(4): 123-130.
+[3] 陈七, 刘八. 生态保护与永续发展[M]. 上海: 环保出版社, 2021.
+
+---
+
+**作者简介**
+作者，某大学农艺与生物工学院教授，专攻动物行为与生态工艺研究，致力于传统智慧与现代科技相结合，探索人与自然和谐共生之道。
\ No newline at end of file
Index: poc.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/poc.py b/poc.py
--- a/poc.py	(revision ccffed1d69c1e025eee3502f8a1a3c919fe4fb52)
+++ b/poc.py	(date 1735635217756)
@@ -2,12 +2,21 @@
 import http.client
 import logging
 import os
+from operator import itemgetter
+from typing import List
 
 from dotenv import load_dotenv
 from langchain_community.chat_models.tongyi import ChatTongyi
 from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory
-from langchain_core.messages import HumanMessage
+from langchain_core.messages import HumanMessage, BaseMessage, AIMessage, ToolMessage, SystemMessage, trim_messages
 from langchain_core.runnables import RunnableWithMessageHistory
+from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
+from langchain_core.runnables import RunnablePassthrough
+from langchain_core.runnables.history import RunnableWithMessageHistory
+from langchain_openai import OpenAIEmbeddings
+from langchain_openai.chat_models import ChatOpenAI
+from langchain_chroma import Chroma
+import tiktoken
 
 
 def setup_logging():
@@ -47,6 +56,36 @@
     return '\n'.join(lines).strip()  # 确保返回的内容不包含多余的空白字符
 
 
+def str_token_counter(text: str) -> int:
+    enc = tiktoken.get_encoding("o200k_base")
+    return len(enc.encode(text))
+
+
+def tiktoken_counter(messages: List[BaseMessage]) -> int:
+    num_tokens = 3
+    tokens_per_message = 3
+    tokens_per_name = 1
+    for msg in messages:
+        if isinstance(msg, HumanMessage):
+            role = "user"
+        elif isinstance(msg, AIMessage):
+            role = "assistant"
+        elif isinstance(msg, ToolMessage):
+            role = "tool"
+        elif isinstance(msg, SystemMessage):
+            role = "system"
+        else:
+            raise ValueError(f"Unsupported messages type {msg.__class__}")
+        num_tokens += (
+                tokens_per_message
+                + str_token_counter(role)
+                + str_token_counter(msg.content)
+        )
+        if msg.name:
+            num_tokens += tokens_per_name + str_token_counter(msg.name)
+    return num_tokens
+
+
 if __name__ == "__main__":
     setup_logging()
 
@@ -54,8 +93,7 @@
     load_dotenv()
 
     # 使用os.getenv获取API key，并提供错误处理
-    api_key = os.getenv("DASHSCOPE_API_KEY")
-    if not api_key:
+    if not os.getenv("DASHSCOPE_API_KEY"):
         raise ValueError("请在.env文件中设置 DASHSCOPE_API_KEY")
 
     # 创建聊天模型
@@ -74,8 +112,50 @@
         return store[session_id]
 
 
-    # 将聊天模型与历史记录包装在一起
-    with_message_history = RunnableWithMessageHistory(chatLLM, get_session_history)
+    # 创建向量存储和检索器
+    vectorstore = Chroma(
+        collection_name="ai_learning",
+        embedding_function=OpenAIEmbeddings(),
+        persist_directory="vectordb"
+    )
+    retriever = vectorstore.as_retriever(search_type="similarity")
+
+    # 创建消息修剪器
+    trimmer = trim_messages(
+        max_tokens=4096,
+        strategy="last",
+        token_counter=tiktoken_counter,
+        include_system=True,
+    )
+
+    # 创建聊天模型链
+    prompt = ChatPromptTemplate.from_messages(
+        [
+            (
+                "system",
+                """You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.
+                Context: {context}""",
+            ),
+            MessagesPlaceholder(variable_name="history"),
+            ("human", "{question}"),
+        ]
+    )
+
+
+    def format_docs(docs):
+        return "\n\n".join(doc.page_content for doc in docs)
+
+
+    context = itemgetter("question") | retriever | format_docs
+    first_step = RunnablePassthrough.assign(context=context)
+    chain = first_step | prompt | trimmer | chatLLM
+
+    with_message_history = RunnableWithMessageHistory(
+        chain,
+        get_session_history=get_session_history,
+        input_messages_key="question",
+        history_messages_key="history",
+    )
 
     # 配置会话ID
     config = {"configurable": {"session_id": "default_session"}}
Index: requirements.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/requirements.txt b/requirements.txt
--- a/requirements.txt	(revision ccffed1d69c1e025eee3502f8a1a3c919fe4fb52)
+++ b/requirements.txt	(date 1735631426115)
@@ -1,4 +1,9 @@
 langchain
 langchain-community
+
+langchain-chroma
+chromadb
+
 dashscope
+
 python-dotenv
\ No newline at end of file
